{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2008fa7",
   "metadata": {},
   "source": [
    "# 1. Running and tracking machine learning experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36be61d6",
   "metadata": {},
   "source": [
    "## 1.0. The data we use: Palmer Pinguins\n",
    "\n",
    "Data were collected and made available by Dr. Kristen Gorman and the Palmer Station, Antarctica LTER, a member of the Long Term Ecological Research Network. It provides a great dataset for data exploration & visualization, as an alternative to iris.\n",
    "\n",
    "We will use this dataset in classification setting to predict the penguins’ species from anatomical information.\n",
    "\n",
    "Each penguin is from one of the three following species: Adelie, Gentoo, and Chinstrap.\n",
    "\n",
    "![palmer penguins](../resources/palmer_penguins.png \"Palmer Penguins\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706b6ce1",
   "metadata": {},
   "source": [
    "This problem is a classification problem since the target is categorical. We will use features based on penguins’ culmen measurement.\n",
    "\n",
    "![Culmen features](../resources/culmen_depth.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dee973",
   "metadata": {},
   "source": [
    "## 1.1. Load and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5501ff60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Culmen Length (mm)</th>\n",
       "      <th>Culmen Depth (mm)</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>44.5</td>\n",
       "      <td>14.7</td>\n",
       "      <td>Gentoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>50.4</td>\n",
       "      <td>15.3</td>\n",
       "      <td>Gentoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>35.9</td>\n",
       "      <td>19.2</td>\n",
       "      <td>Adelie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>40.9</td>\n",
       "      <td>13.7</td>\n",
       "      <td>Gentoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>51.1</td>\n",
       "      <td>16.3</td>\n",
       "      <td>Gentoo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Culmen Length (mm)  Culmen Depth (mm) Species\n",
       "245                44.5               14.7  Gentoo\n",
       "210                50.4               15.3  Gentoo\n",
       "21                 35.9               19.2  Adelie\n",
       "161                40.9               13.7  Gentoo\n",
       "228                51.1               16.3  Gentoo"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "culmen_columns = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\"]\n",
    "target_column = \"Species\"\n",
    "\n",
    "data_path = \"../data/penguins_classification.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "757404bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data, target = data[culmen_columns], data[target_column]\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data, target, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b33dd0e",
   "metadata": {},
   "source": [
    "## 1.2. The modelling: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9daa4c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=3, max_leaf_nodes=4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=3, max_leaf_nodes=4)\n",
    "tree.fit(data_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55f76a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the DecisionTreeClassifier: 96.5%\n"
     ]
    }
   ],
   "source": [
    "test_score = tree.score(data_test, target_test)\n",
    "print(f\"Accuracy of the DecisionTreeClassifier: {test_score:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3780fd",
   "metadata": {},
   "source": [
    "## 1.3. MLflow Stores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cded149",
   "metadata": {},
   "source": [
    "### Tracking stores\n",
    "\n",
    "MLflow supports two types of backend stores: file store and database-backed store.\n",
    "\n",
    "- Local file path (specified as file:/my/local/dir), where data is just directly stored locally. Defaults to `mlruns/`.\n",
    "- Database encoded as +://:<password>@:/. Mlflow supports the dialects mysql, mssql, sqlite, and postgresql. For more details, see SQLAlchemy database uri.\n",
    "- HTTP server (specified as https://my-server:5000), which is a server hosting an MLFlow tracking server.\n",
    "- Databricks workspace (specified as databricks or as databricks://, a Databricks CLI profile.)\n",
    "\n",
    "### Artifact stores\n",
    "Where you store models, plots and other stuff.\n",
    "\n",
    "- Amazon S3\n",
    "- Azure Blob Storage\n",
    "- Google Cloud Storage\n",
    "- FTP server\n",
    "- SFTP Server\n",
    "- NFS\n",
    "- HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98893984",
   "metadata": {},
   "source": [
    "## 1.4. Setup and configure the tracking server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150febdf",
   "metadata": {},
   "source": [
    "We want to use a database as a tracking store and a local directory as artifact store.\n",
    "Using a database is required for later steps in the tutorial, like managing deployments. In this case, artifacts are stored under the local ./mlruns directory, and MLflow entities are inserted in a SQLite database file mlruns.db.\n",
    "\n",
    "\n",
    "![tracking setup](../resources/tracking_setup.png)\n",
    "\n",
    "\n",
    "Run to start the tracking server:\n",
    "\n",
    "```mlflow server --backend-store-uri sqlite:///mflow.db --default-artifact-root mlruns/ --host 0.0.0.0 --port 5000```\n",
    "\n",
    "in a terminal. Make sure you run it inside the virtual environment! Put `pipenv run` in front of it.\n",
    "\n",
    "Now you should be able to see the Tracking UI in a browser at `http://0.0.0.0:5000`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a947eab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "447b5615",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_server_uri = \"http://0.0.0.0:5000\"   # set to your server URI\n",
    "mlflow.set_tracking_uri(remote_server_uri)  # or set the MLFLOW_TRACKING_URI in the env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36fa3afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://0.0.0.0:5000'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.tracking.get_tracking_uri()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e930ea21",
   "metadata": {},
   "source": [
    "### Create a new experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21e087de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_name = \"penguin_classification\"\n",
    "mlflow.create_experiment(exp_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fc6a11",
   "metadata": {},
   "source": [
    "## 1.5. Add tracking code to the machine learning experiment above\n",
    "\n",
    "Basic things to track:\n",
    "- Parameters: Key-value input parameters: `mlflow.log_param, mlflow.log_params`\n",
    "- Metrics: Key-value metrics, where the value is numeric (can be updated over the run): `mlflow.log_metric, mlflow.log_metrics`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0765bc20",
   "metadata": {},
   "source": [
    "Recall the following code from above:\n",
    "\n",
    "```python\n",
    "# Load dataset\n",
    "culmen_columns = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\"]\n",
    "target_column = \"Species\"\n",
    "\n",
    "data_path = \"../data/penguins_classification.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Prepare a train-test-split\n",
    "data, target = data[culmen_columns], data[target_column]\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data, target, random_state=0)\n",
    "\n",
    "# Initialize and fit a classifier\n",
    "tree = DecisionTreeClassifier(max_depth=3, max_leaf_nodes=4)\n",
    "tree.fit(data_train, target_train)\n",
    "\n",
    "# Calculate test scores\n",
    "test_score = tree.score(data_test, target_test)\n",
    "print(f\"Accuracy of the DecisionTreeClassifier: {test_score:.1%}\")\n",
    "```\n",
    "\n",
    "\n",
    "Now we add the required code to track the experiment with MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fedeecaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started run aee9784477a64b87800a676c19fb36ac\n",
      "Load dataset...\n",
      "Prepare a train-test-split...\n",
      "Initialize and fit a DecisionTreeClassifier with max_depth=3, max_leaf_nodes4\n",
      "Result: Accuracy of the DecisionTreeClassifier: 96.5%\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(exp_name)  # <-- set the experiment we want to track to\n",
    "with mlflow.start_run() as run:         # <-- start a run of the experiment\n",
    "    print(f\"Started run {run.info.run_id}\")\n",
    "    # Load dataset\n",
    "    print(\"Load dataset...\")\n",
    "    culmen_columns = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\"]\n",
    "    target_column = \"Species\"\n",
    "\n",
    "    data_path = \"../data/penguins_classification.csv\"\n",
    "    data = pd.read_csv(data_path)\n",
    "\n",
    "    # Prepare a train-test-split\n",
    "    print(\"Prepare a train-test-split...\")\n",
    "    data, target = data[culmen_columns], data[target_column]\n",
    "    data_train, data_test, target_train, target_test = train_test_split(\n",
    "        data, target, random_state=0)\n",
    "\n",
    "    # Initialize and fit a classifier\n",
    "    max_depth = 3\n",
    "    max_leaf_nodes = 4\n",
    "    print(f\"Initialize and fit a DecisionTreeClassifier with max_depth={max_depth}, max_leaf_nodes{max_leaf_nodes}\")\n",
    "    \n",
    "    mlflow.log_params(            # <-- Track parameters\n",
    "        {\"max_depth\": max_depth, \n",
    "         \"max_leaf_nodes\": max_leaf_nodes}\n",
    "    )\n",
    "    tree = DecisionTreeClassifier(\n",
    "        max_depth=max_depth,\n",
    "        max_leaf_nodes=max_leaf_nodes\n",
    "    )\n",
    "    tree.fit(data_train, target_train)\n",
    "\n",
    "    # Calculate test scores\n",
    "    test_score = tree.score(data_test, target_test)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_score)   # <-- Track metrics\n",
    "    print(f\"Result: Accuracy of the DecisionTreeClassifier: {test_score:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344a6d30",
   "metadata": {},
   "source": [
    "Have a look at the tracking UI to see how it played out!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b28e17d",
   "metadata": {},
   "source": [
    "## 1.6. Exercise: track some more stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a513541",
   "metadata": {},
   "source": [
    "What else could we want to track?\n",
    "\n",
    "Examples:  \n",
    "- Code Version: Git commit hash used for the run (if it was run from an MLflow Project)\n",
    "- Start & End Time: Start and end time of the run\n",
    "- Source: what code run?\n",
    "- Plots.\n",
    "- Properties of the input data\n",
    "- Model artifacts\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac48edd",
   "metadata": {},
   "source": [
    "### Exercises: \n",
    "- Track the properties of the input data as parameters. (Hint: `data.shape[0]` gives the number of samples in a dataframe)\n",
    "- Track the notebook 'source code'. (Hint: `mlflow.log_artifact()` takes a path and copies the file to the artifact store.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2150c6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started run 433b40f89b784e98b09f1a8d0235579e\n",
      "Load dataset...\n",
      "Prepare a train-test-split...\n",
      "Initialize and fit a DecisionTreeClassifier with max_depth=3, max_leaf_nodes4\n",
      "Result: Accuracy of the DecisionTreeClassifier: 96.5%\n"
     ]
    }
   ],
   "source": [
    "# EXERCISE:\n",
    "\n",
    "mlflow.set_experiment(exp_name)  # <-- set the experiment we want to track to\n",
    "with mlflow.start_run() as run:         # <-- start a run of the experiment\n",
    "    print(f\"Started run {run.info.run_id}\")\n",
    "    # Load dataset\n",
    "    print(\"Load dataset...\")\n",
    "    culmen_columns = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\"]\n",
    "    target_column = \"Species\"\n",
    "\n",
    "    data_path = \"../data/penguins_classification.csv\"\n",
    "    data = pd.read_csv(data_path)\n",
    "\n",
    "    # Prepare a train-test-split\n",
    "    print(\"Prepare a train-test-split...\")\n",
    "    data, target = data[culmen_columns], data[target_column]\n",
    "    data_train, data_test, target_train, target_test = train_test_split(\n",
    "        data, target, random_state=0)\n",
    "\n",
    "    # Initialize and fit a classifier\n",
    "    max_depth = 3\n",
    "    max_leaf_nodes = 4\n",
    "    print(f\"Initialize and fit a DecisionTreeClassifier with max_depth={max_depth}, max_leaf_nodes{max_leaf_nodes}\")\n",
    "    \n",
    "    mlflow.log_params(            # <-- Track parameters\n",
    "        {\"max_depth\": max_depth, \n",
    "         \"max_leaf_nodes\": max_leaf_nodes}\n",
    "    )\n",
    "    tree = DecisionTreeClassifier(\n",
    "        max_depth=max_depth,\n",
    "        max_leaf_nodes=max_leaf_nodes\n",
    "    )\n",
    "    tree.fit(data_train, target_train)\n",
    "\n",
    "    # Calculate test scores\n",
    "    test_score = tree.score(data_test, target_test)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_score)   # <-- Track metrics\n",
    "    print(f\"Result: Accuracy of the DecisionTreeClassifier: {test_score:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a39f8f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started run 8d29a05e9363452ea7281da00295a109\n",
      "Load dataset...\n",
      "Prepare a train-test-split...\n",
      "Initialize and fit a DecisionTreeClassifier with max_depth=3, max_leaf_nodes4\n",
      "Result: Accuracy of the DecisionTreeClassifier: 96.5%\n"
     ]
    }
   ],
   "source": [
    "# POSSIBLE SOLUTION:\n",
    "\n",
    "mlflow.set_experiment(exp_name)\n",
    "with mlflow.start_run() as run:\n",
    "    print(f\"Started run {run.info.run_id}\")\n",
    "    # Load dataset\n",
    "    print(\"Load dataset...\")\n",
    "    culmen_columns = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\"]\n",
    "    target_column = \"Species\"\n",
    "\n",
    "    data_path = \"../data/penguins_classification.csv\"\n",
    "    data = pd.read_csv(data_path)\n",
    "    mlflow.log_param(\"num_samples\", data.shape[0])  # <-- ADDED: track the number of samples in the dataset\n",
    "\n",
    "    # Prepare a train-test-split\n",
    "    print(\"Prepare a train-test-split...\")\n",
    "    data, target = data[culmen_columns], data[target_column]\n",
    "    data_train, data_test, target_train, target_test = train_test_split(\n",
    "        data, target, random_state=0)\n",
    "\n",
    "    # Initialize and fit a classifier\n",
    "    max_depth = 3\n",
    "    max_leaf_nodes = 4\n",
    "    print(f\"Initialize and fit a DecisionTreeClassifier with max_depth={max_depth}, max_leaf_nodes{max_leaf_nodes}\")\n",
    "    \n",
    "    mlflow.log_params(\n",
    "        {\"max_depth\": max_depth, \n",
    "         \"max_leaf_nodes\": max_leaf_nodes}\n",
    "    )\n",
    "    tree = DecisionTreeClassifier(\n",
    "        max_depth=max_depth,\n",
    "        max_leaf_nodes=max_leaf_nodes\n",
    "    )\n",
    "    tree.fit(data_train, target_train)\n",
    "\n",
    "    # Calculate test scores\n",
    "    test_score = tree.score(data_test, target_test)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_score)\n",
    "    mlflow.log_artifact(\"1_Run and track experiments.ipynb\")  # <-- ADDED: track the source code of the notebook\n",
    "    print(f\"Result: Accuracy of the DecisionTreeClassifier: {test_score:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9548fff0",
   "metadata": {},
   "source": [
    "## 1.7. Log the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee84310",
   "metadata": {},
   "source": [
    "We want to store the model artifacts to reuse it for deployment or later experimentation.\n",
    "Since we used a scikit-learn model here, we can use the build-in module to store the model in sklearn format. \n",
    "\n",
    "```mlflow.sklearn.log_model(tree, \"model\")```\n",
    "\n",
    "There are buildin modules for all kind of types of models, as well as the possibility to specify a custom format. Even autologging is available!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98ca2b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started run 6754c826986f4639a2ba5514020a9f58\n",
      "Load dataset...\n",
      "Prepare a train-test-split...\n",
      "Initialize and fit a DecisionTreeClassifier with max_depth=3, max_leaf_nodes4\n",
      "Result: Accuracy of the DecisionTreeClassifier: 96.5%\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(exp_name)  # <-- set the experiment we want to track to\n",
    "with mlflow.start_run() as run:         # <-- start a run of the experiment\n",
    "    print(f\"Started run {run.info.run_id}\")\n",
    "    # Load dataset\n",
    "    print(\"Load dataset...\")\n",
    "    culmen_columns = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\"]\n",
    "    target_column = \"Species\"\n",
    "\n",
    "    data_path = \"../data/penguins_classification.csv\"\n",
    "    data = pd.read_csv(data_path)\n",
    "    mlflow.log_param(\"num_samples\", data.shape[0])  # <-- track the number of samples in the dataset\n",
    "\n",
    "    # Prepare a train-test-split\n",
    "    print(\"Prepare a train-test-split...\")\n",
    "    data, target = data[culmen_columns], data[target_column]\n",
    "    data_train, data_test, target_train, target_test = train_test_split(\n",
    "        data, target, random_state=0)\n",
    "\n",
    "    # Initialize and fit a classifier\n",
    "    max_depth = 3\n",
    "    max_leaf_nodes = 4\n",
    "    print(f\"Initialize and fit a DecisionTreeClassifier with max_depth={max_depth}, max_leaf_nodes{max_leaf_nodes}\")\n",
    "    \n",
    "    mlflow.log_params(            # <-- Track parameters\n",
    "        {\"max_depth\": max_depth, \n",
    "         \"max_leaf_nodes\": max_leaf_nodes}\n",
    "    )\n",
    "    tree = DecisionTreeClassifier(\n",
    "        max_depth=max_depth,\n",
    "        max_leaf_nodes=max_leaf_nodes\n",
    "    )\n",
    "    tree.fit(data_train, target_train)\n",
    "\n",
    "    # Calculate test scores\n",
    "    test_score = tree.score(data_test, target_test)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_score)   # <-- Track metrics\n",
    "    print(f\"Result: Accuracy of the DecisionTreeClassifier: {test_score:.1%}\")\n",
    "    \n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(tree, \"model\")  # <-- Log the model\n",
    "    mlflow.log_artifact(\"1_Run and track experiments.ipynb\")  # <-- track the source code of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4d31206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice: Run the experiment (in the above cell) with different model parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcaf369",
   "metadata": {},
   "source": [
    "## 1.8. Compare models in the UI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8461ec0c",
   "metadata": {},
   "source": [
    "## 1.9. Optional: Add a signature to the model\n",
    "\n",
    "Define what the model expects and enforce later in deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd07df45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types.schema import Schema, ColSpec\n",
    "\n",
    "input_schema = Schema([\n",
    "  ColSpec(\"double\", \"Culmen Length (mm)\"),\n",
    "  ColSpec(\"double\", \"Culmen Depth (mm)\"),\n",
    "])\n",
    "output_schema = Schema([ColSpec(\"string\")])\n",
    "\n",
    "signature = ModelSignature(inputs=input_schema, outputs=output_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35afcf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started run d981dd2939c748fe9c7142dde9c832a8\n",
      "Load dataset...\n",
      "Prepare a train-test-split...\n",
      "Initialize and fit a DecisionTreeClassifier with max_depth=3, max_leaf_nodes4\n",
      "Result: Accuracy of the DecisionTreeClassifier: 96.5%\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(exp_name)\n",
    "with mlflow.start_run() as run:\n",
    "    print(f\"Started run {run.info.run_id}\")\n",
    "    # Load dataset\n",
    "    print(\"Load dataset...\")\n",
    "    culmen_columns = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\"]\n",
    "    target_column = \"Species\"\n",
    "\n",
    "    data_path = \"../data/penguins_classification.csv\"\n",
    "    data = pd.read_csv(data_path)\n",
    "    mlflow.log_param(\"num_samples\", data.shape[0])\n",
    "\n",
    "    # Prepare a train-test-split\n",
    "    print(\"Prepare a train-test-split...\")\n",
    "    data, target = data[culmen_columns], data[target_column]\n",
    "    data_train, data_test, target_train, target_test = train_test_split(\n",
    "        data, target, random_state=0)\n",
    "\n",
    "    # Initialize and fit a classifier\n",
    "    max_depth = 3\n",
    "    max_leaf_nodes = 4\n",
    "    print(f\"Initialize and fit a DecisionTreeClassifier with max_depth={max_depth}, max_leaf_nodes{max_leaf_nodes}\")\n",
    "    \n",
    "    mlflow.log_params(\n",
    "        {\"max_depth\": max_depth, \n",
    "         \"max_leaf_nodes\": max_leaf_nodes}\n",
    "    )\n",
    "    tree = DecisionTreeClassifier(\n",
    "        max_depth=max_depth,\n",
    "        max_leaf_nodes=max_leaf_nodes\n",
    "    )\n",
    "    tree.fit(data_train, target_train)\n",
    "\n",
    "    # Calculate test scores\n",
    "    test_score = tree.score(data_test, target_test)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_score)\n",
    "    print(f\"Result: Accuracy of the DecisionTreeClassifier: {test_score:.1%}\")\n",
    "    \n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(tree, \"model\", signature=signature)  # <-- Now log the model with a signature\n",
    "    mlflow.log_artifact(\"1_Run and track experiments.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8b7642",
   "metadata": {},
   "source": [
    "## 1.10. Use the model to predict locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9550aa26",
   "metadata": {},
   "source": [
    "Now we pick a model, retrieve it and make a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70f86ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Adelie', 'Chinstrap', 'Adelie', 'Chinstrap', 'Adelie',\n",
       "       'Chinstrap', 'Gentoo', 'Adelie', 'Gentoo', 'Adelie', 'Adelie',\n",
       "       'Gentoo', 'Gentoo', 'Adelie', 'Adelie', 'Gentoo', 'Gentoo',\n",
       "       'Gentoo', 'Chinstrap', 'Adelie', 'Chinstrap', 'Adelie',\n",
       "       'Chinstrap', 'Gentoo', 'Adelie', 'Adelie', 'Gentoo', 'Chinstrap',\n",
       "       'Gentoo', 'Gentoo', 'Adelie', 'Adelie', 'Adelie', 'Gentoo',\n",
       "       'Gentoo', 'Adelie', 'Chinstrap', 'Gentoo', 'Chinstrap', 'Adelie',\n",
       "       'Adelie', 'Adelie', 'Adelie', 'Gentoo', 'Adelie', 'Adelie',\n",
       "       'Chinstrap', 'Gentoo', 'Gentoo', 'Chinstrap', 'Adelie', 'Adelie',\n",
       "       'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Gentoo', 'Adelie',\n",
       "       'Adelie', 'Chinstrap', 'Adelie', 'Adelie', 'Adelie', 'Gentoo',\n",
       "       'Adelie', 'Adelie', 'Adelie', 'Gentoo', 'Adelie', 'Gentoo',\n",
       "       'Adelie', 'Chinstrap', 'Adelie', 'Adelie', 'Gentoo', 'Adelie',\n",
       "       'Chinstrap', 'Adelie', 'Adelie', 'Gentoo', 'Adelie', 'Gentoo',\n",
       "       'Chinstrap', 'Adelie', 'Chinstrap', 'Gentoo'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logged_model = 'runs:/d981dd2939c748fe9c7142dde9c832a8/model'\n",
    "\n",
    "# Load model as a Sklearn Model.\n",
    "loaded_model = mlflow.sklearn.load_model(logged_model)\n",
    "\n",
    "# Predict on a Pandas DataFrame.\n",
    "loaded_model.predict(pd.DataFrame(data_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
